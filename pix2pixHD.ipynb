{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fitted-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "introductory-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLReLU(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels, out_channels, kernel_size=3,\n",
    "                 stride=2, padding=1, padding_mode='reflect'):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
    "                          stride=stride, padding=padding, padding_mode=padding_mode)\n",
    "        self.lrelu = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.lrelu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sporting-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConvInReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 kernel_size=3, stride=2,\n",
    "                 padding=1, output_padding=1):\n",
    "        super().__init__()\n",
    "        self.upconv = nn.ConvTranspose2d(in_channels, out_channels,\n",
    "                                   kernel_size=kernel_size, stride=stride,\n",
    "                                   padding=padding, output_padding=output_padding)\n",
    "        self.insnorm = nn.InstanceNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.upconv(x)\n",
    "        x = self.insnorm(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "taken-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTanh(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                       kernel_size=7, stride=1,\n",
    "                       padding=3, padding_mode='reflect'):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
    "                             stride=stride, padding=padding, padding_mode=padding_mode)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "minor-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvIn(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels, out_channels, kernel_size=3,\n",
    "                 stride=2, padding=1, padding_mode='reflect'):\n",
    "        super().__init__()\n",
    "        self.conv=nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
    "                          stride=stride, padding=padding, padding_mode=padding_mode)\n",
    "        self.insnorm=nn.InstanceNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.insnorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "amended-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvInReLU(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels, out_channels, kernel_size=3,\n",
    "                 stride=2, padding=1, padding_mode='reflect'):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
    "                          stride=stride, padding=padding, padding_mode=padding_mode)\n",
    "        self.insnorm = nn.InstanceNorm2d(out_channels, affine=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.insnorm(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "formed-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv_in_relu = ConvInReLU(in_channels, in_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_in = ConvIn(in_channels, in_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        fx = self.conv_in_relu(x)\n",
    "        fx = self.conv_in(fx)\n",
    "        return fx + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-observation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nearby-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalGenerator(nn.Module):\n",
    "    def __init__(self, in_channels=3, hid_channels=64, out_channels=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Input= ConvInReLU(in_channels, hid_channels, kernel_size=7,\n",
    "                               stride=1, padding=3, padding_mode='reflect')\n",
    "        \n",
    "        self.DownStage=nn.Sequential()\n",
    "        self.DownStage.add_module('block0', ConvInReLU(1*hid_channels, 2*hid_channels))\n",
    "        self.DownStage.add_module('block1', ConvInReLU(2*hid_channels, 4*hid_channels))\n",
    "        self.DownStage.add_module('block2', ConvInReLU(4*hid_channels, 8*hid_channels))\n",
    "        \n",
    "        self.ResStage=nn.Sequential()\n",
    "        self.ResStage.add_module('block0', ResidualBlock(8*hid_channels))\n",
    "        self.ResStage.add_module('block1', ResidualBlock(8*hid_channels))\n",
    "        self.ResStage.add_module('block2', ResidualBlock(8*hid_channels))\n",
    "        self.ResStage.add_module('block3', ResidualBlock(8*hid_channels))\n",
    "        self.ResStage.add_module('block4', ResidualBlock(8*hid_channels))\n",
    "        self.ResStage.add_module('block5', ResidualBlock(8*hid_channels))\n",
    "        self.ResStage.add_module('block6', ResidualBlock(8*hid_channels))\n",
    "        self.ResStage.add_module('block7', ResidualBlock(8*hid_channels))\n",
    "        self.ResStage.add_module('block8', ResidualBlock(8*hid_channels))\n",
    "        \n",
    "        self.UpStage = nn.Sequential()\n",
    "        self.UpStage.add_module('block0', UpConvInReLU(8*hid_channels, 4*hid_channels))\n",
    "        self.UpStage.add_module('block1', UpConvInReLU(4*hid_channels, 2*hid_channels))\n",
    "        self.UpStage.add_module('block2', UpConvInReLU(2*hid_channels, 1*hid_channels))\n",
    "        \n",
    "        self.Output=ConvTanh(hid_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.Input(x)\n",
    "        x = self.DownStage(x)\n",
    "        x = self.ResStage(x)\n",
    "        x = self.UpStage(x)\n",
    "        x = self.Output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "oriental-hamburg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConvInReLU(\n",
       "   (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n",
       "   (insnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Sequential(\n",
       "   (block0): ConvInReLU(\n",
       "     (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
       "     (insnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (block1): ConvInReLU(\n",
       "     (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
       "     (insnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (block2): ConvInReLU(\n",
       "     (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
       "     (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (block0): ResidualBlock(\n",
       "     (conv_in_relu): ConvInReLU(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv_in): ConvIn(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     )\n",
       "   )\n",
       "   (block1): ResidualBlock(\n",
       "     (conv_in_relu): ConvInReLU(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv_in): ConvIn(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     )\n",
       "   )\n",
       "   (block2): ResidualBlock(\n",
       "     (conv_in_relu): ConvInReLU(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv_in): ConvIn(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     )\n",
       "   )\n",
       "   (block3): ResidualBlock(\n",
       "     (conv_in_relu): ConvInReLU(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv_in): ConvIn(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     )\n",
       "   )\n",
       "   (block4): ResidualBlock(\n",
       "     (conv_in_relu): ConvInReLU(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv_in): ConvIn(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     )\n",
       "   )\n",
       "   (block5): ResidualBlock(\n",
       "     (conv_in_relu): ConvInReLU(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv_in): ConvIn(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     )\n",
       "   )\n",
       "   (block6): ResidualBlock(\n",
       "     (conv_in_relu): ConvInReLU(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv_in): ConvIn(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     )\n",
       "   )\n",
       "   (block7): ResidualBlock(\n",
       "     (conv_in_relu): ConvInReLU(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv_in): ConvIn(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     )\n",
       "   )\n",
       "   (block8): ResidualBlock(\n",
       "     (conv_in_relu): ConvInReLU(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "       (relu): ReLU(inplace=True)\n",
       "     )\n",
       "     (conv_in): ConvIn(\n",
       "       (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
       "       (insnorm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (block0): UpConvInReLU(\n",
       "     (upconv): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "     (insnorm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (block1): UpConvInReLU(\n",
       "     (upconv): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "     (insnorm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       "   (block2): UpConvInReLU(\n",
       "     (upconv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "     (insnorm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "     (relu): ReLU()\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = GlobalGenerator()\n",
    "list(gen.children())[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "champion-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalEnhancer(nn.Module):\n",
    "    def __init__(self, in_channels=3, hid_channels=32, out_channels=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.Input=ConvInReLU(in_channels, hid_channels, kernel_size=7,\n",
    "                              stride=1, padding=3, padding_mode='reflect')\n",
    "        \n",
    "        self.DownStage=nn.Sequential()\n",
    "        self.DownStage.add_module('block0', ConvInReLU(1*hid_channels, 2*hid_channels))\n",
    "        \n",
    "        self.AvgPool=nn.AvgPool2d(3, stride=2, padding=1, count_include_pad=False)\n",
    "        generator=GlobalGenerator(in_channels, 2*hid_channels, out_channels)\n",
    "        self.InsideGenerator=nn.Sequential(*list(generator.children())[:-1])\n",
    "        \n",
    "        self.ResStage=nn.Sequential()\n",
    "        self.ResStage.add_module('block0', ResidualBlock(2*hid_channels))\n",
    "        self.ResStage.add_module('block1', ResidualBlock(2*hid_channels))\n",
    "        self.ResStage.add_module('block2', ResidualBlock(2*hid_channels))\n",
    "        \n",
    "        self.UpStage = nn.Sequential()\n",
    "        self.UpStage.add_module('block0', UpConvInReLU(2*hid_channels, 1*hid_channels))\n",
    "        \n",
    "        self.Output=ConvTanh(hid_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y1 = self.Input(x)\n",
    "        y1 = self.DownStage(y1)\n",
    "        \n",
    "        y0 = self.AvgPool(x)\n",
    "        y0 = self.InsideGenerator(y0)\n",
    "        \n",
    "        y = self.ResStage(y0+y1)\n",
    "        y = self.UpStage(y)\n",
    "        y = self.Output(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "consolidated-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LocalEnhancer()\n",
    "p = model(torch.rand(1, 3, 1024, 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "frank-therapy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1024, 2048])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "infinite-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, hid_channels=64, out_channels=1):\n",
    "        super().__init__()\n",
    "        self.Input = ConvLReLU(in_channels, hid_channels,\n",
    "                              kernel_size=4, stride=2, padding=2)\n",
    "        \n",
    "        self.Base = nn.Sequential()\n",
    "        self.Base.add_module('block0', ConvInReLU(hid_channels, 2*hid_channels,\n",
    "                                                 kernel_size=4, stride=2, padding=2))\n",
    "        self.Base.add_module('block1', ConvInReLU(2*hid_channels, 4*hid_channels,\n",
    "                                                 kernel_size=4, stride=2, padding=2))\n",
    "        self.Base.add_module('block2', ConvInReLU(4*hid_channels, 8*hid_channels,\n",
    "                                                 kernel_size=4, stride=1, padding=2))\n",
    "        \n",
    "        self.Output = nn.Conv2d(8*hid_channels, out_channels,\n",
    "                                kernel_size=4, stride=1, padding=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = self.Input(x)\n",
    "        x1 = self.Base.block0(x0)\n",
    "        x2 = self.Base.block1(x1)\n",
    "        x_ = self.Base.block2(x2)\n",
    "        x3 = self.Output(x_)\n",
    "        return [x0, x1, x2, x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "north-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dressed-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model(torch.rand(1, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "indoor-renaissance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adjusted-package",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 129, 129])\n",
      "torch.Size([1, 128, 65, 65])\n",
      "torch.Size([1, 256, 33, 33])\n",
      "torch.Size([1, 1, 35, 35])\n"
     ]
    }
   ],
   "source": [
    "for pi in p:\n",
    "    print(pi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cultural-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleDiscriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, hid_channels=64, out_channels=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.discriminator0=Discriminator(in_channels, hid_channels,\n",
    "                                          out_channels)\n",
    "        self.discriminator1=Discriminator(in_channels, hid_channels,\n",
    "                                          out_channels)\n",
    "        self.discriminator2=Discriminator(in_channels, hid_channels,\n",
    "                                          out_channels)\n",
    "        \n",
    "        self.AvgPool=nn.AvgPool2d(3, stride=2, padding=1,\n",
    "                                  count_include_pad=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = self.discriminator0(x)\n",
    "        x1_ = self.AvgPool(x)\n",
    "        x1 = self.discriminator1(x1_)\n",
    "        x2_ = self.AvgPool(x1_)\n",
    "        x2 = self.discriminator2(x2_)\n",
    "        return [x0, x1, x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fiscal-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = MultiScaleDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "sensitive-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = d(torch.rand(1, 3, 256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "medical-pearl",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "integral-electron",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 129, 129])\n",
      "torch.Size([1, 128, 65, 65])\n",
      "torch.Size([1, 256, 33, 33])\n",
      "torch.Size([1, 1, 35, 35])\n",
      "\n",
      "torch.Size([1, 64, 65, 65])\n",
      "torch.Size([1, 128, 33, 33])\n",
      "torch.Size([1, 256, 17, 17])\n",
      "torch.Size([1, 1, 19, 19])\n",
      "\n",
      "torch.Size([1, 64, 33, 33])\n",
      "torch.Size([1, 128, 17, 17])\n",
      "torch.Size([1, 256, 9, 9])\n",
      "torch.Size([1, 1, 11, 11])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pi in p:\n",
    "    for pj in pi:\n",
    "        \n",
    "        print(pj.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "strong-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceWiseAvgPool(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.n_channels=n_channels\n",
    "    \n",
    "    def forward(self, x, instance):\n",
    "        x_mean = torch.zeros_like(x)\n",
    "        classes = torch.unique(instance, return_inverse=False,\n",
    "                               return_counts=False)\n",
    "        nB = x.size(0)\n",
    "        for c in classes:\n",
    "            for b in range(nB):\n",
    "                idx = torch.nonzero(instance[b:b+1]==c, as_tuple=False)\n",
    "                for k in range(self.n_channels):\n",
    "                    x_ins = x[idx[:, 0] + b, idx[:, 1] + k, idx[:, 2], idx[:, 3]]\n",
    "                    mean_feat = torch.mean(x_ins).expand_as(x_ins)\n",
    "                    x_mean[idx[:, 0] + b, idx[:, 1] + k, idx[:, 2], idx[:, 3]]=mean_feat\n",
    "        return x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "public-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, hid_channels=16, out_channels=1):\n",
    "        super().__init__()\n",
    "        self.Input = ConvInReLU(in_channels, hid_channels,\n",
    "                               kernel_size=7, stride=1, padding=3)\n",
    "        \n",
    "        self.DownStage = nn.Sequential()\n",
    "        self.DownStage.add_module('block0', ConvInReLU(1*hid_channels, 2*hid_channels,\n",
    "                                               kernel_size=3, stride=2, padding=1))\n",
    "        self.DownStage.add_module('block1', ConvInReLU(2*hid_channels, 4*hid_channels,\n",
    "                                               kernel_size=3, stride=2, padding=1))\n",
    "        self.DownStage.add_module('block2', ConvInReLU(4*hid_channels, 8*hid_channels,\n",
    "                                               kernel_size=3, stride=2, padding=1))\n",
    "        self.DownStage.add_module('block3', ConvInReLU(8*hid_channels, 16*hid_channels,\n",
    "                                               kernel_size=3, stride=2, padding=1))\n",
    "        \n",
    "        self.UpStage = nn.Sequential()\n",
    "        self.UpStage.add_module('block0', UpConvInReLU(16*hid_channels, 8*hid_channels,\n",
    "                                                      kernel_size=3, stride=2, padding=1))\n",
    "        self.UpStage.add_module('block1', UpConvInReLU(8*hid_channels, 4*hid_channels,\n",
    "                                                      kernel_size=3, stride=2, padding=1))\n",
    "        self.UpStage.add_module('block2', UpConvInReLU(4*hid_channels, 2*hid_channels,\n",
    "                                                      kernel_size=3, stride=2, padding=1))\n",
    "        self.UpStage.add_module('block3', UpConvInReLU(2*hid_channels, 1*hid_channels,\n",
    "                                                      kernel_size=3, stride=2, padding=1))\n",
    "        \n",
    "        self.Output=ConvTanh(hid_channels, out_channels,\n",
    "                            kernel_size=7, stride=1, padding=3)\n",
    "        \n",
    "        #self.InstAvgPool=InstanceWiseAvgPool(out_channels)\n",
    "    def instancewise_average_pooling(self, x, inst):\n",
    "        '''\n",
    "        Applies instance-wise average pooling.\n",
    "\n",
    "        Given a feature map of size (b, c, h, w), the mean is computed for each b, c\n",
    "        across all h, w of the same instance\n",
    "        '''\n",
    "        x_mean = torch.zeros_like(x)\n",
    "        classes = torch.unique(inst, return_inverse=False, return_counts=False) # gather all unique classes present\n",
    "\n",
    "        for i in classes:\n",
    "            for b in range(x.size(0)):\n",
    "                indices = torch.nonzero(inst[b:b+1] == i, as_tuple=False) # get indices of all positions equal to class i\n",
    "                for j in range(1):\n",
    "                    x_ins = x[indices[:, 0] + b, indices[:, 1] + j, indices[:, 2], indices[:, 3]]\n",
    "                    mean_feat = torch.mean(x_ins).expand_as(x_ins)\n",
    "                    x_mean[indices[:, 0] + b, indices[:, 1] + j, indices[:, 2], indices[:, 3]] = mean_feat\n",
    "\n",
    "        return x_mean\n",
    "        \n",
    "    def forward(self, x, instance):\n",
    "        x0 = self.Input(x)\n",
    "        x1 = self.DownStage(x0)\n",
    "        x2 = self.UpStage(x1)\n",
    "        x3 = self.Output(x2)\n",
    "        #y = self.InstAvgPool(x3, instance)\n",
    "        y = self.instancewise_average_pooling(x3, instance)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "inner-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "painted-furniture",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-bb23fdc4bc23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\akana\\anaconda3\\envs\\deepl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-80a40644fd55>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, instance)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mx3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m#y = self.InstAvgPool(x3, instance)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstancewise_average_pooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-80a40644fd55>\u001b[0m in \u001b[0;36minstancewise_average_pooling\u001b[1;34m(self, x, inst)\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# get indices of all positions equal to class i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                     \u001b[0mx_ins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m                     \u001b[0mmean_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_ins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_ins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                     \u001b[0mx_mean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "p = m(torch.rand(10, 3, 256, 256), torch.rand(10, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-wound",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
